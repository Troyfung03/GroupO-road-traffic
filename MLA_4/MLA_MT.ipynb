{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q4  MLA && PCA - Traffic Density -> Traffic Duration / Traffic Clustering - GET DATA HOURLY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MULTITHREADING CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s0614\\AppData\\Local\\Temp\\ipykernel_29272\\2634708108.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting traffic_20230903_hour_0.csv\n",
      "File traffic_20230903_hour_0.csv saved.\n",
      "end of the hour 0\n",
      "Getting traffic_20230903_hour_1.csv\n",
      "File traffic_20230903_hour_1.csv saved.\n",
      "end of the hour 1\n",
      "Getting traffic_20230903_hour_2.csv\n",
      "File traffic_20230903_hour_2.csv saved.\n",
      "end of the hour 2\n",
      "Getting traffic_20230903_hour_3.csv\n",
      "File traffic_20230903_hour_3.csv saved.\n",
      "end of the hour 3\n",
      "Getting traffic_20230903_hour_4.csv\n",
      "File traffic_20230903_hour_4.csv saved.\n",
      "end of the hour 4\n",
      "Getting traffic_20230903_hour_5.csv\n",
      "File traffic_20230903_hour_5.csv saved.\n",
      "end of the hour 5\n",
      "Getting traffic_20230903_hour_6.csv\n",
      "File traffic_20230903_hour_6.csv saved.\n",
      "end of the hour 6\n",
      "Getting traffic_20230903_hour_7.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 83\u001b[0m\n\u001b[0;32m     80\u001b[0m totals \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Create a ThreadPoolExecutor\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mThreadPoolExecutor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Loop over each minute of the current hour\u001b[39;49;00m\n\u001b[0;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mminute\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfetch_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminute\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhour\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotals\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\concurrent\\futures\\_base.py:647\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[1;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[1;32m--> 647\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\concurrent\\futures\\thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[1;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[1;32m--> 235\u001b[0m         \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\threading.py:1119\u001b[0m, in \u001b[0;36mThread.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1119\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1121\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[0;32m   1122\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[0;32m   1123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\threading.py:1139\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1140\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m   1141\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import xml.etree.ElementTree as ET\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = datetime.strptime('20230903', '%Y%m%d')\n",
    "end_date = datetime.strptime('20230904', '%Y%m%d')\n",
    "\n",
    "# Define the base URL\n",
    "base_url = 'https://api.data.gov.hk/v1/historical-archive/get-file?url=https%3A%2F%2Fresource.data.one.gov.hk%2Ftd%2Ftraffic-detectors%2FrawSpeedVol-all.xml&time='\n",
    "\n",
    "# Function to fetch data for a given minute\n",
    "def fetch_data(minute, current_date, hour, totals):\n",
    "    # Generate the timestamp for the current minute\n",
    "    timestamp = current_date.strftime('%Y%m%d') + '-' + f'{hour:02d}{minute:02d}'\n",
    "\n",
    "    # Fetch the data for the current timestamp\n",
    "    response = requests.get(base_url + timestamp)\n",
    "\n",
    "    # Check the status of the response\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch data for {timestamp}, status code: {response.status_code}\")\n",
    "        return\n",
    "\n",
    "    root = ET.fromstring(response.content)\n",
    "\n",
    "    # Extract the data and add it to the dictionary\n",
    "    for period in root.findall('.//periods/period'):\n",
    "        for detector in period.findall('.//detectors/detector'):\n",
    "            detector_id = detector.find('detector_id').text\n",
    "\n",
    "            for lane in detector.findall('.//lanes/lane'):\n",
    "                lane_id_element = lane.find('lane_id')\n",
    "                if lane_id_element is not None:\n",
    "                    lane_id = lane_id_element.text\n",
    "                else:\n",
    "                    print(\"lane_id element not found\")\n",
    "                    continue\n",
    "\n",
    "                speed_element = lane.find('speed')\n",
    "\n",
    "                occupancy = int(lane.find('occupancy').text)\n",
    "                volume = int(lane.find('volume').text)\n",
    "\n",
    "                # Check if the 'speed' element is present and contains a valid float\n",
    "                if speed_element is not None:\n",
    "                    try:\n",
    "                        speed = float(speed_element.text)\n",
    "                    except ValueError:\n",
    "                        print(f\"Invalid speed: {speed_element.text}\")\n",
    "                        continue\n",
    "\n",
    "                    # Add the speed to the total for the current detector and lane id\n",
    "                    if (detector_id, lane_id) not in totals:\n",
    "                        totals[(detector_id, lane_id)] = [speed, 1, occupancy, volume]\n",
    "                    else:\n",
    "                        totals[(detector_id, lane_id)][0] += speed\n",
    "                        totals[(detector_id, lane_id)][1] += 1\n",
    "                        totals[(detector_id, lane_id)][2] += occupancy\n",
    "                        totals[(detector_id, lane_id)][3] += volume\n",
    "\n",
    "# Loop over the date range\n",
    "current_date = start_date\n",
    "while current_date <= end_date:\n",
    "    # Loop over each hour of the current day\n",
    "    for hour in range(0, 24):\n",
    "        # Save the DataFrame to a CSV file\n",
    "        filename = f\"traffic_{current_date.strftime('%Y%m%d')}_hour_{hour}.csv\"\n",
    "        \n",
    "        print('Getting', filename);\n",
    "\n",
    "        if os.path.isfile(filename):\n",
    "            print(f\"File {filename} already exists. Skipping this hour.\")\n",
    "            continue\n",
    "\n",
    "        # Initialize a dictionary to store the total speed and count for each detector and lane\n",
    "        totals = {}\n",
    "\n",
    "        # Create a ThreadPoolExecutor\n",
    "        with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "            # Loop over each minute of the current hour\n",
    "            for minute in range(0, 60):\n",
    "                executor.submit(fetch_data, minute, current_date, hour, totals)\n",
    "\n",
    "        # Calculate the average speed for each detector and lane id and add it to the list\n",
    "        data = [{'detectorID': detector_id, 'laneType': lane_id, 'speed': total_speed / count, 'totalOccupancy': total_occupancy, 'totalVolume': total_volume}\n",
    "                for (detector_id, lane_id), (total_speed, count, total_occupancy, total_volume) in totals.items()]\n",
    "\n",
    "        # Convert the list into a DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        # Save the DataFrame to a CSV file\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"File {filename} saved.\")\n",
    "\n",
    "        print(f\"end of the hour {hour}\")\n",
    "    # Move to the next day\n",
    "    current_date += timedelta(days=1)\n",
    "\n",
    "print(f\"finished fetch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
